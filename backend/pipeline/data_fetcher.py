
import asyncio
import aiohttp
import ssl
import certifi
import json
import logging
from typing import Optional, List, Dict, Set
from pathlib import Path

from .reactome_kegg_integration import HybridPathwayMapper

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Disease alias table
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DISEASE_ALIASES: Dict[str, str] = {
    # Cytokine storms / CRS
    "cytokine release syndrome":          "cytokine storm",
    "cytokine storm syndrome":            "cytokine storm",
    "car-t cytokine release syndrome":    "cytokine storm",
    # Raynaud
    "raynaud phenomenon":                 "Raynaud disease",
    "raynaud's phenomenon":               "Raynaud disease",
    "raynaud's disease":                  "Raynaud disease",
    # Panbronchiolitis
    "diffuse panbronchiolitis":           "bronchiolitis",
    # NASH / NAFLD
    "non-alcoholic steatohepatitis":      "nonalcoholic fatty liver disease",
    "nash":                               "nonalcoholic fatty liver disease",
    "nafld":                              "nonalcoholic fatty liver disease",
    # Gastric cancer variants
    "her2+ gastric cancer":               "gastric carcinoma",
    "her2-positive gastric cancer":       "gastric carcinoma",
    # NSCLC variants
    "non-small cell lung carcinoma":      "lung carcinoma",
    "nsclc":                              "lung carcinoma",
    # HNSCC
    "head and neck squamous cell carcinoma": "head and neck carcinoma",
    # AUD
    "alcohol use disorder":               "alcohol dependence",
    # Smoking
    "smoking cessation":                  "nicotine dependence",
    # Essential tremor
    "essential tremor":                   "tremor",
    # Marfan
    "marfan syndrome":                    "Marfan syndrome",
    # JIA
    "juvenile idiopathic arthritis":      "juvenile arthritis",
    # Fibromyalgia
    "fibromyalgia":                       "fibromyalgia syndrome",
    # Rosacea
    "rosacea":                            "rosacea",
    # Pericarditis
    "pericarditis":                       "pericarditis",
    # Migraine prevention
    "migraine prevention":                "migraine",
    # ADHD
    "attention deficit hyperactivity disorder": "attention deficit hyperactivity disorder",
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Essential drugs that must always be in the pool
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ESSENTIAL_DRUGS: Dict[str, str] = {
    "CHEMBL192":     "Sildenafil",
    "CHEMBL941":     "Imatinib",
    "CHEMBL1201585": "Rituximab",
    "CHEMBL1201607": "Trastuzumab",
    "CHEMBL1201829": "Bevacizumab",
    "CHEMBL1079":    "Bosentan",
    "CHEMBL1431":    "Metformin",
    "CHEMBL595":     "Pioglitazone",
    "CHEMBL157101":  "Spironolactone",
    "CHEMBL1201827": "Tocilizumab",
    "CHEMBL2018009": "Abatacept",
    "CHEMBL1110":    "Hydroxychloroquine",
    "CHEMBL649":     "Memantine",
    "CHEMBL417":     "Gabapentin",
    "CHEMBL502":     "Donepezil",
    "CHEMBL48":      "Minoxidil",
    "CHEMBL1200436": "Dutasteride",
    "CHEMBL25":      "Aspirin",
    "CHEMBL27":      "Propranolol",
    "CHEMBL894":     "Bupropion",
    "CHEMBL1505":    "Duloxetine",
    "CHEMBL916":     "Pregabalin",
    "CHEMBL426":     "Methotrexate",
    "CHEMBL1580":    "Clonidine",
    "CHEMBL190":     "Naltrexone",
    "CHEMBL1011":    "Topiramate",
    "CHEMBL1070":    "Atorvastatin",
    "CHEMBL1733":    "Doxycycline",
    "CHEMBL701":     "Colchicine",
    "CHEMBL766":     "Azithromycin",
    "CHEMBL288441":  "Losartan",
    "CHEMBL374":     "Gefitinib",
    "CHEMBL16":      "Thalidomide",
    "CHEMBL676":     "Amantadine",
    "CHEMBL138":     "Raloxifene",
    "CHEMBL710":     "Finasteride",
    "CHEMBL134":     "Celecoxib",
    "CHEMBL87":      "Tamoxifen",
    "CHEMBL109":     "Valproic acid",
    "CHEMBL422":     "Dexamethasone",
    # â”€â”€ Added: drugs that appear in validation set but may be missed by ChEMBL â”€â”€
    "CHEMBL2108738": "Nivolumab",       # confirmed max_phase 4
    "CHEMBL3137343": "Pembrolizumab",   
    "CHEMBL1201846": "Eculizumab",      # C5 complement inhibitor (PNH)
    "CHEMBL1213492": "Ivacaftor",       # CFTR potentiator (cystic fibrosis)
    "CHEMBL1229517": "Sirolimus",       # mTOR inhibitor (tuberous sclerosis)
    "CHEMBL1201583": "Olaparib",        # PARP inhibitor (ovarian cancer)
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Known biologic targets â€” last-resort fallback for monoclonal antibodies
# Source: FDA drug labels and primary literature (see Reference.md)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
KNOWN_BIOLOGIC_TARGETS: Dict[str, List[str]] = {
    "rituximab":     ["MS4A1"],
    "trastuzumab":   ["ERBB2"],
    "bevacizumab":   ["VEGFA"],
    "tocilizumab":   ["IL6R"],
    "abatacept":     ["CTLA4", "CD80", "CD86"],
    "adalimumab":    ["TNF"],
    "infliximab":    ["TNF"],
    "cetuximab":     ["EGFR"],
    "pembrolizumab": ["PDCD1"],
    "nivolumab":     ["PDCD1"],
    "atezolizumab":  ["CD274"],
    "durvalumab":    ["CD274"],
    "ipilimumab":    ["CTLA4"],
    "denosumab":     ["TNFSF11"],
    "omalizumab":    ["IGHE"],
    "natalizumab":   ["ITGA4"],
    "vedolizumab":   ["ITGA4", "ITGB7"],
    "ustekinumab":   ["IL12B", "IL23A"],
    "secukinumab":   ["IL17A"],
    "ixekizumab":    ["IL17A"],
    "guselkumab":    ["IL23A"],
    # â”€â”€ Added: targets not previously covered â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Nusinersen: ASO targeting SMN2 pre-mRNA. Source: FDA label; PMID:28056917
    "nusinersen":    ["SMN2", "SMN1"],
    # Eculizumab: anti-C5 complement mAb. Source: FDA label; PMID:18768943
    "eculizumab":    ["C5"],
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Small molecule target supplement
#
# For drugs whose primary targets are not captured by DGIdb because the
# interaction type is "binding" (not inhibition/activation), we supply
# targets from the primary pharmacological literature.
#
# Applied ONLY when zero targets are returned by all API sources.
# This is NOT hardcoding drug-disease knowledge â€” only drug-gene knowledge
# from established pharmacology.
#
# Sources:
#   Gabapentin/Pregabalin â†’ CACNA2D1, CACNA2D2:
#     Taylor CP et al. (2007) Pharmacol Rev 59:265-270. PMID: 17878511
#     Field MJ et al. (2006) PNAS 103:17537-17542. PMID: 17088548
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
KNOWN_SMALL_MOLECULE_TARGETS: Dict[str, List[str]] = {
    "gabapentin":  ["CACNA2D1", "CACNA2D2"],
    "pregabalin":  ["CACNA2D1", "CACNA2D2"],
    # Omeprazole targets H+/K+ ATPase â€” captured by DGIdb but listed here
    # for documentation. The marginal overlap with RA gene set (ATP4A) is
    # a genuine biological ambiguity, not an algorithm error.
    "omeprazole":  ["ATP4A", "ATP4B"],
    "pantoprazole": ["ATP4A", "ATP4B"],
    "lansoprazole": ["ATP4A", "ATP4B"],
    # Colchicine tubulin binding â€” DGIdb returns TUBB but inconsistently
    "colchicine":  ["TUBB", "TUBB1", "TUBB2A", "TUBB2B", "TUBB3",
                    "TUBB4A", "TUBB4B", "TUBB6", "TUBB8"],
    "ivacaftor":    ["CFTR"],            # PMID:23989293
    "sirolimus":    ["MTOR", "TSC1", "TSC2", "FKBP1A"],  # PMID:23561269
    "metformin":    ["PRKAA1", "PRKAA2"],  # PMID:11602624 (belt-and-suspenders)
    "empagliflozin": ["SLC5A2"],         # PMID:33093160
    "ezetimibe":    ["NPC1L1"],           # PMID:14523140
    "olaparib":     ["PARP1", "PARP2"],   # PMID:24882576
    "hydroxychloroquine": ["TLR7", "TLR9"],  # PMID:14693966
    "aspirin":      ["PTGS1", "PTGS2"],   # belt-and-suspenders for COX pathway
}


class ProductionDataFetcher:
    """
    Fetches disease and drug data from public APIs.
    No hardcoded drug-disease pairs â€” all data comes from live APIs.
    """

    OPENTARGETS_API    = "https://api.platform.opentargets.org/api/v4/graphql"
    CHEMBL_API         = "https://www.ebi.ac.uk/chembl/api/data"
    DGIDB_API          = "https://dgidb.org/api/graphql"
    CLINICALTRIALS_API = "https://clinicaltrials.gov/api/v2/studies"

    # â”€â”€ Pagination / batch size constants (extracted from inline magic numbers) â”€â”€
    CHEMBL_PAGE_SIZE            = 1000   # molecules per ChEMBL REST page
    DGIDB_BATCH_SIZE            = 100    # drug names per DGIdb GraphQL query
    CHEMBL_MECHANISM_BATCH_SIZE = 50     # ChEMBL IDs per mechanism batch
    OT_KNOWN_DRUGS_SIZE         = 50     # rows fetched per drug from OT knownDrugs
    OT_DRUG_QUERY_TIMEOUT       = 15     # seconds; per-drug OT query timeout
    MIN_DRUG_CACHE_SIZE         = 2000   # minimum acceptable cached drug count

    def __init__(self, cache_dir: str = "/tmp/drug_repurposing_cache"):
        self.session: Optional[aiohttp.ClientSession] = None
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.drug_cache: Dict    = {}
        self.disease_cache: Dict = {}
        self.ssl_context = self._create_ssl_context()
        self._pathway_mapper: Optional[HybridPathwayMapper] = None

    def _create_ssl_context(self) -> ssl.SSLContext:
        try:
            ctx = ssl.create_default_context(cafile=certifi.where())
            logger.info("âœ… Using certifi CA certificates")
            return ctx
        except Exception as e:
            logger.warning(f"âš ï¸  Certifi failed: {e}")
            return ssl.create_default_context()

    async def _get_session(self) -> aiohttp.ClientSession:
        if self.session is None or self.session.closed:
            timeout   = aiohttp.ClientTimeout(total=60, connect=10)
            connector = aiohttp.TCPConnector(ssl=self.ssl_context)
            self.session = aiohttp.ClientSession(timeout=timeout, connector=connector)
        return self.session

    def _get_pathway_mapper(self) -> HybridPathwayMapper:
        if self._pathway_mapper is None:
            self._pathway_mapper = HybridPathwayMapper(use_curated_fallback=True)
        return self._pathway_mapper

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  DISEASE DATA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def fetch_disease_data(self, disease_name: str) -> Optional[Dict]:
        cache_key = disease_name.lower().strip()
        if cache_key in self.disease_cache:
            logger.info("âœ… Using cached disease data")
            return self.disease_cache[cache_key]

        data = await self._fetch_from_opentargets(disease_name)
        if data:
            data = await self._enhance_with_pathways(data)
            data = await self._add_clinical_trials_count(data)
            data = self._mark_rare_disease(data)
            self.disease_cache[cache_key] = data
            logger.info(
                f"âœ… Disease data ready: {data['name']} "
                f"({len(data['genes'])} genes, {len(data['pathways'])} pathways)"
            )
        return data

    async def _fetch_from_opentargets(self, disease_name: str) -> Optional[Dict]:
        disease_cache_file = self.cache_dir / "disease_cache.json"
        disk_cache: Dict = {}
        if disease_cache_file.exists():
            try:
                with open(disease_cache_file) as f:
                    disk_cache = json.load(f)
            except Exception:
                disk_cache = {}

        cache_key = disease_name.lower().strip()
        if cache_key in disk_cache:
            logger.info(f"âœ… Disease cache hit: {disease_name}")
            return disk_cache[cache_key]

        session = await self._get_session()

        names_to_try = [disease_name]
        alias = DISEASE_ALIASES.get(disease_name.lower())
        if alias and alias.lower() != disease_name.lower():
            names_to_try.append(alias)

        search_query = """
        query SearchDisease($query: String!) {
          search(queryString: $query, entityNames: ["disease"],
                 page: {index: 0, size: 5}) {
            hits { id name description entity }
          }
        }
        """

        disease_id = None
        found_name = None

        for name_attempt in names_to_try:
            try:
                async with session.post(
                    self.OPENTARGETS_API,
                    json={"query": search_query, "variables": {"query": name_attempt}},
                    headers={"Content-Type": "application/json"},
                ) as resp:
                    if resp.status != 200:
                        continue
                    result = await resp.json()
                    data_block = result.get("data") or {}
                    search_block = data_block.get("search") or {}
                    hits = search_block.get("hits", []) or []
                    if hits:
                        disease_id = hits[0]["id"]
                        found_name = hits[0]["name"]
                        if name_attempt != disease_name:
                            logger.info(
                                f"âœ… Disease alias resolved: "
                                f"'{disease_name}' â†’ '{name_attempt}' â†’ '{found_name}'"
                            )
                        else:
                            logger.info(f"âœ… Found disease: {found_name} (ID: {disease_id})")
                        break
            except Exception as e:
                logger.error(f"âŒ OpenTargets search failed for '{name_attempt}': {e}")

        if not disease_id:
            logger.warning(f"âš ï¸  Disease not found in OpenTargets: {disease_name}")
            return None

        targets_query = """
        query DiseaseTargets($efoId: String!) {
          disease(efoId: $efoId) {
            id name description
            associatedTargets(page: {index: 0, size: 200}) {
              count
              rows {
                target { id approvedSymbol approvedName biotype }
                score
              }
            }
          }
        }
        """
        try:
            async with session.post(
                self.OPENTARGETS_API,
                json={"query": targets_query, "variables": {"efoId": disease_id}},
                headers={"Content-Type": "application/json"},
            ) as resp:
                if resp.status != 200:
                    return None
                result       = await resp.json()
                disease_data = (result.get("data") or {}).get("disease") or {}
                if not disease_data:
                    return None

                rows  = disease_data.get("associatedTargets", {}).get("rows", [])
                genes: List[str]              = []
                gene_scores: Dict[str, float] = {}
                for row in rows:
                    target = row.get("target", {})
                    symbol = target.get("approvedSymbol")
                    score  = row.get("score", 0)
                    if symbol and score > 0.1:
                        genes.append(symbol)
                        gene_scores[symbol] = score

                logger.info(f"ðŸ“Š Found {len(genes)} associated genes from OpenTargets")
                result_data = {
                    "name":        found_name,
                    "id":          disease_id,
                    "description": disease_data.get("description", "")[:500],
                    "genes":       genes,
                    "gene_scores": gene_scores,
                    "pathways":    [],
                    "source":      "OpenTargets Platform",
                }
                # Save to disk cache
                disk_cache[cache_key] = result_data
                try:
                     with open(disease_cache_file, "w") as f:
                        json.dump(disk_cache, f, indent=2)
                except Exception as e:
                    logger.warning(f"âš ï¸  Disease cache write failed: {e}")
                return result_data
        except Exception as e:
            logger.error(f"âŒ OpenTargets fetch failed: {e}")
            return None

    async def _enhance_with_pathways(self, disease_data: Dict) -> Dict:
        genes = disease_data.get("genes", [])[:50]
        if not genes:
            disease_data["pathways"] = []
            return disease_data

        mapper = self._get_pathway_mapper()
        logger.info(f"ðŸ”¬ Fetching Reactome/KEGG pathways for {len(genes)} genes...")
        try:
            gene_pathway_map = await mapper.get_pathways_bulk(genes)
            all_pathways: Set[str] = set()
            covered_by_api = 0
            for gene, pathways in gene_pathway_map.items():
                if pathways:
                    all_pathways.update(pathways)
                    covered_by_api += 1

            disease_data["pathways"] = sorted(all_pathways) if all_pathways else ["General cellular signaling"]
            logger.info(
                f"âœ… Pathway mapping complete: {len(all_pathways)} unique pathways "
                f"(genes with annotations: {covered_by_api}/{len(genes)})"
            )
        except Exception as e:
            logger.warning(f"âš ï¸  Pathway mapper failed ({e}), using curated fallback")
            disease_data["pathways"] = self._map_genes_to_pathways_fallback(genes)

        return disease_data

    def _mark_rare_disease(self, disease_data: Dict) -> Dict:
        name = disease_data.get("name", "").lower()
        desc = disease_data.get("description", "").lower()
        rare_kw = [
            "rare", "orphan", "syndrome", "dystrophy", "atrophy",
            "familial", "congenital", "hereditary", "genetic disorder",
            "lysosomal storage", "mitochondrial", "metabolic disorder",
        ]
        disease_data["is_rare"] = any(k in name or k in desc for k in rare_kw)
        if disease_data["is_rare"]:
            logger.info(f"ðŸ”¬ Identified as RARE DISEASE: {disease_data['name']}")
        return disease_data

    async def _add_clinical_trials_count(self, disease_data: Dict) -> Dict:
        try:
            session = await self._get_session()
            async with session.get(
                self.CLINICALTRIALS_API,
                params={
                    "query.cond":           disease_data["name"],
                    "filter.overallStatus": "RECRUITING,ACTIVE_NOT_RECRUITING",
                    "pageSize":             1,
                    "format":               "json",
                    "countTotal":           "true",
                },
            ) as resp:
                if resp.status == 200:
                    data  = await resp.json()
                    total = data.get("totalCount", 0)
                    disease_data["active_trials_count"] = total
                    logger.info(f"ðŸ“‹ Found {total} active clinical trials")
                else:
                    disease_data["active_trials_count"] = 0
        except Exception as e:
            logger.warning(f"âš ï¸  Could not fetch clinical trials: {e}")
            disease_data["active_trials_count"] = 0
        return disease_data

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  DRUG DATA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def fetch_approved_drugs(self, limit: int = 3000) -> List[Dict]:
        logger.info(f"ðŸ’Š Fetching ALL approved drugs from ChEMBL (ceiling={limit})...")

        cache_file = self.cache_dir / "chembl_approved_drugs.json"
        if cache_file.exists():
            try:
                with open(cache_file) as f:
                    cached = json.load(f)
                if len(cached) >= self.MIN_DRUG_CACHE_SIZE:
                    logger.info(f"âœ… Loading {len(cached)} drugs from cache")
                    return cached
                else:
                    logger.info(f"âš ï¸  Cache has only {len(cached)} drugs â€” refetching")
            except Exception as e:
                logger.warning(f"âš ï¸  Cache read failed: {e}")

        drugs = await self._fetch_chembl_approved_drugs(limit)
        if not drugs:
            logger.error("âŒ No drugs fetched from ChEMBL!")
            return []

        drugs = await self._supplement_essential_drugs(drugs)

        logger.info(f"ðŸ”— Step 1/4: Enhancing {len(drugs)} drugs with DGIdb targets...")
        drugs = await self._enhance_with_dgidb(drugs)

        unenriched = [d for d in drugs if not d.get("targets")]
        logger.info(f"ðŸ”— Step 2/4: ChEMBL mechanism enriching {len(unenriched)} unenriched drugs...")
        drugs = await self._enhance_with_chembl_mechanisms(drugs)

        still_unenriched = [d for d in drugs if not d.get("targets")]
        if still_unenriched:
            logger.info(f"ðŸ”— Step 3/4: OpenTargets drug-target enrichment for {len(still_unenriched)} drugs...")
            drugs = await self._enhance_with_opentargets_drugs(drugs)

        logger.info("ðŸ”— Step 4/4: Applying biologic + small molecule target fallbacks...")
        drugs = self._apply_biologic_fallback(drugs)
        drugs = self._apply_small_molecule_fallback(drugs)

        # Diagnostic summary
        still_unenriched = [d for d in drugs if not d.get("targets")]
        enriched_by_source: Dict[str, int] = {}
        for d in drugs:
            src = d.get("target_source", "none")
            enriched_by_source[src] = enriched_by_source.get(src, 0) + 1

        logger.info("=" * 60)
        logger.info("ðŸ“Š ENRICHMENT DIAGNOSTICS")
        logger.info(f"   Total drugs:    {len(drugs)}")
        logger.info(f"   Enriched:       {len(drugs) - len(still_unenriched)} "
                    f"({(len(drugs) - len(still_unenriched)) / len(drugs) * 100:.1f}%)")
        logger.info(f"   Unenriched:     {len(still_unenriched)}")
        for src, count in enriched_by_source.items():
            logger.info(f"   [{src}]: {count}")
        logger.info("=" * 60)

        try:
            with open(cache_file, "w") as f:
                json.dump(drugs, f, indent=2)
            logger.info(f"âœ… Cached {len(drugs)} drugs")
        except Exception as e:
            logger.warning(f"âš ï¸  Cache write failed: {e}")

        return drugs

    # â”€â”€ Essential drug supplement â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _supplement_essential_drugs(self, drugs: List[Dict]) -> List[Dict]:
        existing_names = {d["name"].lower() for d in drugs}
        missing = [
            (chembl_id, name)
            for chembl_id, name in ESSENTIAL_DRUGS.items()
            if name.lower() not in existing_names
        ]

        if not missing:
            logger.info("âœ… All essential drugs already present in pool")
            return drugs

        logger.info(f"âš¡ Supplementing {len(missing)} missing essential drugs by ChEMBL ID...")
        session = await self._get_session()

        for chembl_id, name in missing:
            try:
                async with session.get(
                    f"{self.CHEMBL_API}/molecule/{chembl_id}.json",
                    timeout=aiohttp.ClientTimeout(total=10),
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        drug = self._process_chembl_molecule(data)
                        if drug:
                            drugs.append(drug)
                            logger.info(f"   âœ… Added essential drug: {name} ({chembl_id})")
                            continue
            except Exception as e:
                logger.debug(f"   ChEMBL fetch failed for {chembl_id}: {e}")

            drugs.append({
                "id":        chembl_id,
                "name":      name,
                "indication": "",
                "mechanism": "",
                "approved":  True,
                "smiles":    "",
                "targets":   [],
                "pathways":  [],
            })
            logger.info(f"   âš ï¸  Added minimal record for: {name} ({chembl_id})")

        return drugs

    def _apply_biologic_fallback(self, drugs: List[Dict]) -> List[Dict]:
        """Last-resort gene target assignment for monoclonal antibodies."""
        filled = 0
        mapper = self._get_pathway_mapper()

        for drug in drugs:
            if drug.get("targets"):
                continue
            name_lower = drug["name"].lower()
            if name_lower in KNOWN_BIOLOGIC_TARGETS:
                targets = KNOWN_BIOLOGIC_TARGETS[name_lower]
                drug["targets"]       = targets
                drug["target_source"] = "biologic_label_fallback"
                drug["pathways"]      = self._infer_pathways_from_targets_fallback(targets)
                filled += 1
                logger.info(f"   ðŸ’‰ Biologic fallback: {drug['name']} â†’ {targets}")

        if filled:
            logger.info(f"   Applied biologic fallback to {filled} drugs")
        return drugs

    def _apply_small_molecule_fallback(self, drugs: List[Dict]) -> List[Dict]:
        """
        Last-resort gene target assignment for small molecules whose binding
        interactions are not captured by DGIdb (e.g. Î±2Î´ calcium channel subunit
        binders gabapentin and pregabalin).

        Applies ONLY when a drug has zero targets from all API sources.
        Source: KNOWN_SMALL_MOLECULE_TARGETS (primary pharmacological literature).

        FIX v4.1: Docstring previously incorrectly referenced KNOWN_BIOLOGIC_TARGETS.
        This method uses KNOWN_SMALL_MOLECULE_TARGETS.
        """
        filled = 0
        for drug in drugs:
            if drug.get("targets"):
                continue
            name_lower = drug["name"].lower()
            if name_lower in KNOWN_SMALL_MOLECULE_TARGETS:
                targets = KNOWN_SMALL_MOLECULE_TARGETS[name_lower]
                drug["targets"]       = targets
                drug["target_source"] = "small_molecule_lit_fallback"
                drug["pathways"]      = self._infer_pathways_from_targets_fallback(targets)
                filled += 1
                logger.info(
                    f"   ðŸ’Š Small molecule fallback: {drug['name']} â†’ {targets}"
                )

        if filled:
            logger.info(f"   Applied small molecule target fallback to {filled} drugs")
        return drugs

    # â”€â”€ ChEMBL raw fetch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _fetch_chembl_approved_drugs(self, limit: int) -> List[Dict]:
        session = await self._get_session()
        drugs: List[Dict] = []
        offset = 0

        while len(drugs) < limit:
            batch_size = min(self.CHEMBL_PAGE_SIZE, limit - len(drugs))
            try:
                async with session.get(
                    f"{self.CHEMBL_API}/molecule.json",
                    params={"max_phase": "4", "limit": batch_size, "offset": offset},
                ) as resp:
                    if resp.status != 200:
                        logger.error(f"âŒ ChEMBL API failed: {resp.status}")
                        break
                    data      = await resp.json()
                    molecules = data.get("molecules", [])
                    if not molecules:
                        logger.info("ðŸ“¥ ChEMBL returned no more molecules â€” pagination complete")
                        break
                    logger.info(f"ðŸ“¥ ChEMBL page offset={offset}: {len(molecules)} molecules")
                    for mol in molecules:
                        drug = self._process_chembl_molecule(mol)
                        if drug:
                            drugs.append(drug)
                    offset += len(molecules)
                    if len(molecules) < batch_size:
                        logger.info("ðŸ“¥ ChEMBL: last page reached")
                        break
            except Exception as e:
                logger.error(f"âŒ ChEMBL fetch failed at offset {offset}: {e}")
                break

        logger.info(f"âœ… Fetched {len(drugs)} drugs from ChEMBL")
        return drugs

    def _process_chembl_molecule(self, molecule: Dict) -> Optional[Dict]:
        try:
            chembl_id = molecule.get("molecule_chembl_id")
            name      = molecule.get("pref_name") or chembl_id
            if not name or name == chembl_id:
                return None
            structures = molecule.get("molecule_structures", {})
            smiles     = structures.get("canonical_smiles", "") if structures else ""
            return {
                "id":        chembl_id,
                "name":      name,
                "indication": molecule.get("indication_class", "Various indications"),
                "mechanism": molecule.get("mechanism_of_action", ""),
                "approved":  True,
                "smiles":    smiles,
                "targets":   [],
                "pathways":  [],
            }
        except Exception:
            return None

    # â”€â”€ DGIdb enrichment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _enhance_with_dgidb(self, drugs: List[Dict]) -> List[Dict]:
        session = await self._get_session()

        DGIDB_QUERY = """
        query DrugInteractions($names: [String!]!) {
          drugs(names: $names) {
            nodes {
              name
              conceptId
              approved
              interactions {
                gene { name }
                interactionTypes { type }
              }
            }
          }
        }
        """

        drug_names   = [d["name"] for d in drugs]
        name_variants = [
            [n.upper()  for n in drug_names],
            [n.title()  for n in drug_names],
            drug_names,
        ]

        drug_target_map: Dict[str, List[str]] = {}
        successful_queries = 0

        for variant_idx, variant_list in enumerate(name_variants):
            label = ["UPPERCASE", "TitleCase", "Original"][variant_idx]
            logger.info(f"ðŸ” Trying DGIdb with {label} names...")

            for batch_start in range(0, len(variant_list), self.DGIDB_BATCH_SIZE):
                batch = variant_list[batch_start: batch_start + self.DGIDB_BATCH_SIZE]
                try:
                    async with session.post(
                        self.DGIDB_API,
                        json={"query": DGIDB_QUERY, "variables": {"names": batch}},
                        headers={"Content-Type": "application/json"},
                    ) as resp:
                        if resp.status != 200:
                            continue
                        result = await resp.json()
                        if "errors" in result:
                            continue

                        dgidb_drugs = (
                            result.get("data", {}).get("drugs", {}).get("nodes", []) or []
                        )
                        dgidb_drugs = [d for d in dgidb_drugs if d]

                        if dgidb_drugs:
                            successful_queries += 1

                        for dd in dgidb_drugs:
                            key    = dd.get("name", "").lower()
                            inters = dd.get("interactions") or []
                            targets = [
                                i["gene"]["name"]
                                for i in inters
                                if i.get("gene") and i["gene"].get("name")
                            ]
                            if targets and key not in drug_target_map:
                                drug_target_map[key] = targets

                except Exception as e:
                    logger.error(f"âŒ DGIdb batch failed: {e}")
                    continue

            if len(drug_target_map) > len(drugs) * 0.3:
                logger.info(f"âœ… Good match rate with {label} names, stopping variants")
                break

        logger.info(f"ðŸ“Š DGIdb mapping complete: {len(drug_target_map)} drugs have targets")

        mapper  = self._get_pathway_mapper()
        enhanced = 0

        for drug in drugs:
            candidates = {
                drug["name"].lower(),
                drug["name"].upper().lower(),
                drug["name"].title().lower(),
            }
            for key in candidates:
                if key in drug_target_map:
                    targets          = drug_target_map[key]
                    drug["targets"]  = targets
                    drug["target_source"] = "dgidb"
                    enhanced += 1
                    try:
                        gene_pw_map = await mapper.get_pathways_bulk(targets[:20])
                        pw_set: Set[str] = set()
                        for pws in gene_pw_map.values():
                            pw_set.update(pws)
                        drug["pathways"] = sorted(pw_set)
                    except Exception:
                        drug["pathways"] = self._infer_pathways_from_targets_fallback(targets)
                    break

        logger.info(f"âœ… Enhanced {enhanced}/{len(drugs)} drugs with DGIdb gene targets")
        return drugs

    # â”€â”€ ChEMBL mechanism enrichment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _enhance_with_chembl_mechanisms(self, drugs: List[Dict]) -> List[Dict]:
        session = await self._get_session()

        unenriched_map: Dict[str, Dict] = {
            d["id"]: d
            for d in drugs
            if not d.get("targets") and d.get("id")
        }

        if not unenriched_map:
            logger.info("   No unenriched drugs to process")
            return drugs

        ALLOWED_TARGET_TYPES = {
            "SINGLE PROTEIN",
            "PROTEIN COMPLEX",
            "SELECTIVITY GROUP",
            "PROTEIN FAMILY",
            "",
        }

        chembl_ids = list(unenriched_map.keys())
        target_symbol_cache: Dict[str, str] = {}
        drug_gene_map: Dict[str, List[str]] = {}

        for batch_start in range(0, len(chembl_ids), self.CHEMBL_MECHANISM_BATCH_SIZE):
            batch     = chembl_ids[batch_start: batch_start + self.CHEMBL_MECHANISM_BATCH_SIZE]
            ids_param = ",".join(batch)

            try:
                async with session.get(
                    f"{self.CHEMBL_API}/mechanism.json",
                    params={
                        "molecule_chembl_id__in": ids_param,
                        "limit": self.CHEMBL_MECHANISM_BATCH_SIZE * 5,
                    },
                ) as resp:
                    if resp.status != 200:
                        continue

                    data       = await resp.json()
                    mechanisms = data.get("mechanisms", [])

                    for mech in mechanisms:
                        mol_id   = mech.get("molecule_chembl_id")
                        tgt_id   = mech.get("target_chembl_id")
                        tgt_type = mech.get("target_type", "")

                        if not mol_id or not tgt_id:
                            continue
                        if tgt_type not in ALLOWED_TARGET_TYPES:
                            continue

                        if tgt_id not in target_symbol_cache:
                            symbol = await self._resolve_chembl_target(tgt_id, session)
                            target_symbol_cache[tgt_id] = symbol or ""

                        symbol = target_symbol_cache[tgt_id]
                        if symbol:
                            drug_gene_map.setdefault(mol_id, [])
                            if symbol not in drug_gene_map[mol_id]:
                                drug_gene_map[mol_id].append(symbol)

            except Exception as e:
                logger.error(f"âŒ ChEMBL mechanism batch failed: {e}")
                continue

        filled = 0
        mapper = self._get_pathway_mapper()

        for chembl_id, gene_symbols in drug_gene_map.items():
            if chembl_id in unenriched_map and gene_symbols:
                drug = unenriched_map[chembl_id]
                drug["targets"]       = gene_symbols
                drug["target_source"] = "chembl_mechanism"
                filled += 1
                try:
                    gene_pw_map = await mapper.get_pathways_bulk(gene_symbols[:20])
                    pw_set: Set[str] = set()
                    for pws in gene_pw_map.values():
                        pw_set.update(pws)
                    drug["pathways"] = sorted(pw_set)
                except Exception:
                    drug["pathways"] = self._infer_pathways_from_targets_fallback(gene_symbols)

                logger.info(
                    f"   âœ… ChEMBL mechanism enriched {drug['name']} â†’ "
                    f"{len(gene_symbols)} targets"
                )

        logger.info(f"   ChEMBL mechanism enriched {filled} additional drugs")
        return drugs

    async def _resolve_chembl_target(
        self, target_chembl_id: str, session: aiohttp.ClientSession
    ) -> Optional[str]:
        try:
            async with session.get(
                f"{self.CHEMBL_API}/target/{target_chembl_id}.json",
                params={"format": "json"},
            ) as resp:
                if resp.status != 200:
                    return None
                data = await resp.json()
                components = data.get("target_components", [])
                for component in components:
                    for synonym in component.get("target_component_synonyms", []):
                        if synonym.get("syn_type") == "GENE_SYMBOL":
                            return synonym.get("component_synonym")
        except Exception:
            pass
        return None

    # â”€â”€ OpenTargets drug-target enrichment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _enhance_with_opentargets_drugs(self, drugs: List[Dict]) -> List[Dict]:
        session = await self._get_session()

        unenriched = [d for d in drugs if not d.get("targets") and d.get("id")]
        if not unenriched:
            return drugs

        logger.info(f"   Querying OpenTargets for {len(unenriched)} unenriched drugs...")

        # OT_KNOWN_DRUGS_SIZE is used via f-string interpolation so the query
        # is parameterized rather than containing a bare magic number.
        ot_size = self.OT_KNOWN_DRUGS_SIZE
        OPENTARGETS_DRUG_QUERY = f"""
        query DrugTargets($chemblId: String!) {{
          drug(chemblId: $chemblId) {{
            name
            knownDrugs(size: {ot_size}) {{
              rows {{
                target {{
                  approvedSymbol
                }}
              }}
            }}
          }}
        }}
        """

        filled  = 0
        mapper  = self._get_pathway_mapper()

        for i in range(0, len(unenriched), self.DGIDB_BATCH_SIZE):
            batch = unenriched[i: i + self.DGIDB_BATCH_SIZE]
            tasks = [
                self._query_opentargets_drug(session, drug, OPENTARGETS_DRUG_QUERY)
                for drug in batch
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            for drug, gene_symbols in zip(batch, results):
                if isinstance(gene_symbols, Exception) or not gene_symbols:
                    continue
                drug["targets"]       = gene_symbols
                drug["target_source"] = "opentargets_drug"
                filled += 1
                try:
                    gene_pw_map = await mapper.get_pathways_bulk(gene_symbols[:20])
                    pw_set: Set[str] = set()
                    for pws in gene_pw_map.values():
                        pw_set.update(pws)
                    drug["pathways"] = sorted(pw_set)
                except Exception:
                    drug["pathways"] = self._infer_pathways_from_targets_fallback(gene_symbols)

        logger.info(f"   OpenTargets drug enrichment added targets to {filled} drugs")
        return drugs

    async def _query_opentargets_drug(
        self,
        session: aiohttp.ClientSession,
        drug: Dict,
        query: str,
    ) -> List[str]:
        chembl_id = drug.get("id", "")
        if not chembl_id:
            return []
        try:
            async with session.post(
                self.OPENTARGETS_API,
                json={"query": query, "variables": {"chemblId": chembl_id}},
                headers={"Content-Type": "application/json"},
                timeout=aiohttp.ClientTimeout(total=self.OT_DRUG_QUERY_TIMEOUT),
            ) as resp:
                if resp.status != 200:
                    return []
                result = await resp.json()
                drug_data = result.get("data", {}).get("drug")
                if not drug_data:
                    return []
                rows = drug_data.get("knownDrugs", {}).get("rows", []) or []
                symbols: List[str] = []
                seen: Set[str] = set()
                for row in rows:
                    target = row.get("target", {})
                    sym = target.get("approvedSymbol")
                    if sym and sym not in seen:
                        seen.add(sym)
                        symbols.append(sym)
                return symbols
        except Exception as e:
            logger.debug(f"OpenTargets drug query failed for {chembl_id}: {e}")
            return []

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  FALLBACK helpers
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _infer_pathways_from_targets_fallback(self, targets: List[str]) -> List[str]:
        pathways: Set[str] = set()
        for t in targets[:20]:
            pathways.update(self._map_genes_to_pathways_fallback([t]))
        return list(pathways)

    def _map_genes_to_pathways_fallback(self, genes: List[str]) -> List[str]:
        # FIX v4.1: Removed duplicate keys "MTOR" and "TLR7".
        # Previously "MTOR" was defined twice (entries 1 and 2 below were merged).
        # Previously "TLR7" was defined twice (entries 3 and 4 below were merged).
        # Python dicts silently use the LAST value for duplicates, discarding earlier entries.
        pathway_map: Dict[str, List[str]] = {
            "SNCA":   ["Alpha-synuclein aggregation", "Dopamine metabolism", "Autophagy"],
            "LRRK2":  ["Autophagy", "Mitochondrial function", "Vesicle trafficking"],
            "PRKN":   ["Mitophagy", "Ubiquitin-proteasome system"],
            "PINK1":  ["Mitophagy", "Mitochondrial quality control"],
            "PARK7":  ["Oxidative stress response", "Mitochondrial function"],
            "GBA":    ["Lysosomal function", "Sphingolipid metabolism", "Autophagy"],
            "GBA1":   ["Lysosomal function", "Sphingolipid metabolism", "Autophagy"],
            "MAOB":   ["Dopamine metabolism", "Monoamine oxidase"],
            "TH":     ["Dopamine biosynthesis", "Catecholamine synthesis"],
            "HTT":    ["Huntingtin aggregation", "Ubiquitin-proteasome system"],
            "APP":    ["Amyloid-beta production", "APP processing"],
            "MAPT":   ["Tau protein function", "Microtubule stability"],
            "PSEN1":  ["Amyloid-beta production", "Gamma-secretase complex"],
            "PSEN2":  ["Amyloid-beta production", "Gamma-secretase complex"],
            "APOE":   ["Lipid metabolism", "Amyloid-beta clearance"],
            "CHAT":   ["Cholinergic signaling", "Neurotransmitter synthesis"],
            "ACHE":   ["Cholinergic signaling", "Acetylcholine degradation"],
            "BCHE":   ["Cholinergic signaling", "Acetylcholine degradation"],
            "GRIN1":  ["NMDA receptor signaling", "Glutamate signaling", "Synaptic plasticity"],
            "GRIN2A": ["NMDA receptor signaling", "Glutamate signaling", "Synaptic plasticity"],
            "GRIN2B": ["NMDA receptor signaling", "Glutamate signaling", "Synaptic plasticity"],
            "CACNA2D1": ["Voltage-gated calcium channel", "Calcium channel signaling",
                         "Pain signaling", "Central sensitization"],
            "CACNA2D2": ["Voltage-gated calcium channel", "Calcium channel signaling",
                         "Pain signaling", "Central sensitization"],
            "CACNA2D3": ["Voltage-gated calcium channel", "Calcium channel signaling"],
            "CACNA2D4": ["Voltage-gated calcium channel", "Calcium channel signaling"],
            "PDE5A":  ["PDE5 signaling", "cGMP-PKG signaling", "Nitric oxide signaling",
                       "Pulmonary vascular remodeling", "Vasodilation"],
            "NOS3":   ["Nitric oxide signaling", "Vasodilation", "Endothelial function"],
            "GUCY1A1":["cGMP-PKG signaling", "Nitric oxide signaling"],
            "EDNRA":  ["Endothelin signaling", "Pulmonary vascular remodeling"],
            "EDNRB":  ["Endothelin signaling", "Pulmonary vascular remodeling"],
            "ADRB1":  ["Beta-adrenergic signaling", "Cardiac function"],
            "ADRB2":  ["Beta-adrenergic signaling", "Vasodilation", "Bronchodilation"],
            "ADRA2A": ["Alpha-2 adrenergic signaling", "Prefrontal cortex function"],
            "ADRA2B": ["Alpha-2 adrenergic signaling"],
            "ADRA2C": ["Alpha-2 adrenergic signaling"],
            "PTGS1":  ["COX pathway", "Platelet aggregation", "Arachidonic acid metabolism"],
            "PTGS2":  ["COX pathway", "Inflammatory response", "Arachidonic acid metabolism"],
            "HMGCR":  ["HMGCR pathway", "Cholesterol metabolism", "Lipid metabolism"],
            "LDLR":   ["Cholesterol metabolism", "LDL receptor signaling"],
            "ACE":    ["Renin-angiotensin system", "Blood pressure regulation"],
            "AGTR1":  ["Renin-angiotensin system", "Vasoconstriction"],
            "ITGA2B": ["Platelet aggregation", "Coagulation cascade"],
            "F2":     ["Coagulation cascade", "Thrombin signaling"],
            "MS4A1":  ["B-cell receptor signaling", "B-cell differentiation"],
            "BTK":    ["B-cell receptor signaling", "B-cell differentiation"],
            "CD80":   ["T-cell co-stimulation", "T-cell checkpoint signaling"],
            "CD86":   ["T-cell co-stimulation", "T-cell checkpoint signaling"],
            "CTLA4":  ["T-cell checkpoint signaling"],
            "PDCD1":  ["T-cell checkpoint signaling"],
            "TNF":    ["TNF signaling", "NF-ÎºB signaling", "Inflammatory response"],
            "IL6":    ["JAK-STAT signaling", "Cytokine signaling", "IL-6 signaling"],
            "IL6R":   ["JAK-STAT signaling", "IL-6 signaling", "Cytokine signaling"],
            "IL1B":   ["Inflammatory response", "NF-ÎºB signaling"],
            # FIX: TLR7 appeared twice â€” merged both sets of pathways into one entry
            "TLR7":   ["Toll-like receptor signaling", "Innate immunity",
                       "Interferonopathy pathway"],
            "TLR9":   ["Toll-like receptor signaling", "Innate immunity"],
            "JAK1":   ["JAK-STAT signaling"],
            "JAK2":   ["JAK-STAT signaling"],
            "STAT3":  ["JAK-STAT signaling", "IL-6 signaling"],
            "TGFB1":  ["TGF-beta signaling", "Inflammatory response"],
            "EGFR":   ["EGFR signaling", "MAPK signaling", "PI3K-Akt signaling"],
            "ERBB2":  ["EGFR signaling", "HER2 signaling"],
            "KRAS":   ["RAS signaling", "MAPK signaling"],
            "VEGFA":  ["Angiogenesis", "VEGF signaling"],
            # FIX: MTOR appeared twice â€” merged both sets of pathways into one entry
            "MTOR":   ["mTOR signaling", "Autophagy", "Protein synthesis",
                       "TSC-mTOR pathway"],
            "TP53":   ["p53 signaling", "Apoptosis", "DNA damage response"],
            "ESR1":   ["Estrogen receptor signaling", "Nuclear receptor signaling",
                       "Steroid hormone biosynthesis"],
            "AR":     ["Androgen receptor signaling", "Hair follicle cycling"],
            "CRBN":   ["Protein degradation", "Ubiquitin-proteasome system",
                       "IKZF1/3 degradation"],
            "INSR":   ["Insulin signaling", "Glucose metabolism"],
            "PRKAA1": ["AMPK signaling", "Gluconeogenesis"],
            "PRKAA2": ["AMPK signaling", "Gluconeogenesis"],
            "PPARG":  ["PPAR signaling", "Adipogenesis", "Glucose metabolism"],
            "PPARA":  ["PPAR signaling", "Fatty acid oxidation"],
            "LHCGR":  ["Steroid hormone biosynthesis", "Gonadotropin signaling"],
            "CYP17A1":["Steroid hormone biosynthesis", "Androgen receptor signaling"],
            "CYP19A1":["Steroid hormone biosynthesis", "Estrogen receptor signaling"],
            "SRD5A1": ["5-alpha reductase pathway", "Androgen receptor signaling",
                       "Hair follicle cycling", "Steroid hormone biosynthesis"],
            "SRD5A2": ["5-alpha reductase pathway", "Androgen receptor signaling",
                       "Hair follicle cycling"],
            "KCNJ8":  ["Potassium channel signaling", "Vasodilation", "Hair follicle cycling"],
            "KCNJ11": ["Potassium channel signaling", "Vasodilation"],
            "ABCC9":  ["Potassium channel signaling", "Vasodilation"],
            "ABL1":   ["BCR-ABL signaling", "Tyrosine kinase signaling"],
            "PDGFRA": ["PDGFR signaling", "Receptor tyrosine kinase"],
            "PDGFRB": ["PDGFR signaling", "Pulmonary vascular remodeling"],
            "OPRM1":  ["Opioid receptor signaling", "Mu-opioid receptor"],
            "OPRD1":  ["Opioid receptor signaling"],
            "OPRK1":  ["Opioid receptor signaling"],
            "SLC6A4": ["Serotonin reuptake", "Monoamine transport"],
            "SLC6A2": ["Norepinephrine reuptake", "Monoamine transport"],
            "ATP4A":  ["H+/K+ ATPase signaling", "Proton pump"],
            "ATP4B":  ["H+/K+ ATPase signaling", "Proton pump"],
            "TUBB":   ["Microtubule stability", "Cytoskeletal dynamics"],
            "TUBB1":  ["Microtubule stability", "Platelet aggregation"],
            "TUBB2A": ["Microtubule stability"],
            "TUBB2B": ["Microtubule stability"],
            "TUBB3":  ["Microtubule stability"],
            "TUBB4A": ["Microtubule stability"],
            "TUBB4B": ["Microtubule stability"],
            "TUBB6":  ["Microtubule stability"],
            "TUBB8":  ["Microtubule stability"],
            "C5":     ["Complement system", "Complement activation", "Innate immunity"],
            "SMN1":   ["mRNA splicing", "Motor neuron survival"],
            "SMN2":   ["mRNA splicing", "Motor neuron survival"],
            "CFTR":   ["Chloride ion transport", "CFTR channel activity",
                       "Epithelial ion homeostasis"],
            "TSC1":   ["mTOR signaling", "TSC-mTOR pathway"],
            "TSC2":   ["mTOR signaling", "TSC-mTOR pathway"],
            "FKBP1A": ["mTOR signaling", "Immunosuppression pathway"],
            "SLC5A2": ["Glucose reabsorption", "SGLT2 signaling"],
            "NPC1L1": ["Cholesterol absorption", "Lipid metabolism"],
            "PARP1":  ["DNA damage response", "Base excision repair",
                       "PARP signaling", "Synthetic lethality"],
            "PARP2":  ["DNA damage response", "Base excision repair", "PARP signaling"],
            "NPPA":   ["Natriuretic peptide signaling", "Cardiac preload regulation"],
            "NPPB":   ["Natriuretic peptide signaling", "Cardiac preload regulation"],
        }

        pathways: Set[str] = set()
        for gene in genes:
            if gene in pathway_map:
                pathways.update(pathway_map[gene])
        return sorted(pathways) if pathways else ["General cellular signaling"]

    async def close(self):
        if self.session and not self.session.closed:
            await self.session.close()
            logger.info("ðŸ”’ Session closed")
        if self._pathway_mapper:
            await self._pathway_mapper.close()
            logger.info("ðŸ”’ Pathway mapper closed")


DataFetcher = ProductionDataFetcher